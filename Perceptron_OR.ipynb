{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron_OR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrcrdg/jupyter_set/blob/master/Perceptron_OR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PUrEWNVokTq"
      },
      "source": [
        "# Perceptron OR Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAIALPgZorpy"
      },
      "source": [
        "## Setting up the environmentm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "221D3b0Koydg"
      },
      "source": [
        "The Keras framework has been implemented inside the Google Tensorflow API on version 2.0. The Keras framework takes advantage of the optimizations for GPU and also TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jT907oHpabg"
      },
      "source": [
        "The first thing we should do is to update Google Colab tensorflow version <strong>this has to be done at every notebook created</strong>. The tool we'll be using for that is the `pip` tool. It is important that we restart the environment after finishing the installation;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHJ4WOQIyalz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "5ce5dbb6-9cd0-4f86-8760-88594f0dbf96"
      },
      "source": [
        "! pip install tensorflow==2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==2 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (0.33.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (0.1.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (1.11.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (1.17.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (2.0.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2) (1.0.8)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2) (42.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2) (0.16.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2) (2.21.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2) (0.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2) (2.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (0.2.7)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (3.1.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (2019.11.28)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc7WV0-orDGD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c127254e-f8e3-4519-965b-e52b570740ee"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__) # Check the version of the tensorflow library"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8Sij0G6rUTl"
      },
      "source": [
        "## Create the input dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcyzAnTWqwmD"
      },
      "source": [
        "We will also use numpy, thus the import:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULE81emgz6UJ"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEEkkPNGrRbo"
      },
      "source": [
        "Create the truth table for the OR operation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYMrkZFHzpPd"
      },
      "source": [
        "or_truth_table = np.array([[0,0,0],\n",
        "                           [0,1,1],\n",
        "                           [1,0,1],\n",
        "                           [1,1,1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAQV_w2t1f6G"
      },
      "source": [
        "## Creating a Sequential Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Tam5marvDM"
      },
      "source": [
        "Import and instantiate the Sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DbQsrWI0ni7"
      },
      "source": [
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vrCZuKD2HSk"
      },
      "source": [
        "model = Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blzcsuqQ2Kyl"
      },
      "source": [
        "Create a layer with a single neuron. The Dense layer represents a layer of neurons that are completely interconnected with the previous and next layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wybhR07IsVE"
      },
      "source": [
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LgWjpBV2TDJ"
      },
      "source": [
        "model.add(Dense(units=1, input_dim=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw1NEsq-I4QG"
      },
      "source": [
        "Now we need to compile the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7liXdyW6JTRF"
      },
      "source": [
        "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jffX5UztszI"
      },
      "source": [
        "Split our dataset into input and expected values;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7v6XDjsKUmB"
      },
      "source": [
        "X_data = or_truth_table[:,[0,1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZHBR8jWMT_D"
      },
      "source": [
        "Y_data = or_truth_table[:,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXIiKqPjt2Tw"
      },
      "source": [
        "Perform the training (`fit`) operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ymAEEXMMggw"
      },
      "source": [
        "model.fit(x=X_data, y=Y_data, epochs=200, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PgSY7Det78o"
      },
      "source": [
        "Check the error value (`loss`) when predicting using the dataset, i.e., how far off we are from the correct answer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBIv_FYXMvZx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "22fa1f4a-8acd-4ff8-9cd5-0b35cde34eb2"
      },
      "source": [
        "loss_and_metrics = model.evaluate(X_data, Y_data)\n",
        "print(loss_and_metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r4/1 [========================================================================================================================] - 0s 599us/sample - loss: 0.0819\n",
            "0.08190849423408508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zwyVJqIuS52"
      },
      "source": [
        "Now it is time to make predictions using our trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a9WUbyQNJ0l"
      },
      "source": [
        "prediction = model.predict(X_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMG4hM3aNVFd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "edd5c1ff-9e4d-4784-b5d5-d28f78c95d89"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.28700256]\n",
            " [0.75856614]\n",
            " [0.75304747]\n",
            " [1.224611  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3KFfN38uj2H"
      },
      "source": [
        "Convert the output to the desired format:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL802cvMuoQU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "42b95303-027c-4cc7-d64e-af800385f707"
      },
      "source": [
        "print(np.round(prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGdCGC07N8dV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da474788-2f4c-42e3-c1c5-0a4eb6209d98"
      },
      "source": [
        "print(Y_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}